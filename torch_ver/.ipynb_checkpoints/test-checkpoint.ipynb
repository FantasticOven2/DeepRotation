{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3089ccb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fantasticoven/.local/lib/python3.8/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "from tsGaussian.torch_tsgaussian import TangentSpaceGaussian\n",
    "from stable_baselines_utils import TangentSpaceGaussian as TSG\n",
    "# from pytorch3d.transforms.so3 import (\n",
    "#     so3_exp_map,\n",
    "#     so3_relative_angle,\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c929d1d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tg = TangentSpaceGaussian(None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b42c0040",
   "metadata": {},
   "source": [
    "# Test liegroup torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd25bc8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from liegroups.torch import SO3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "76ec1228",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<liegroups.torch.so3.SO3Matrix>\n",
       "| tensor([[[-0.6949,  0.7135,  0.0893],\n",
       "|          [-0.1920, -0.3038,  0.9332],\n",
       "|          [ 0.6930,  0.6313,  0.3481]],\n",
       "| \n",
       "|         [[ 1.0000,  0.0000,  0.0000],\n",
       "|          [ 0.0000,  1.0000,  0.0000],\n",
       "|          [ 0.0000,  0.0000,  1.0000]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C = SO3.exp(torch.Tensor([[1,2,3],\n",
    "                         [0,0,0]]))\n",
    "C"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98c8fe6f",
   "metadata": {},
   "source": [
    "# Test torch_tsgaussian sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "214db66c",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_mu = torch.eye(3).reshape((1,3,3))\n",
    "sigma = torch.ones(3).reshape((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6a17bcce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Device index must not be negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [6]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m R_quat, R_x \u001b[38;5;241m=\u001b[39m \u001b[43mtg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[43mR_mu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DeepRotation/torch_ver/tsGaussian/torch_tsgaussian.py:52\u001b[0m, in \u001b[0;36mTangentSpaceGaussian.rsample\u001b[0;34m(self, R_mu, sigma)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(dev)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# print('sigma: ', sigma)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m omega \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m, sigma)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# print(R_mu.size())\u001b[39;00m\n\u001b[1;32m     54\u001b[0m R_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(R_mu, SO3\u001b[38;5;241m.\u001b[39mexp(omega\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39mas_matrix()\u001b[38;5;241m.\u001b[39mto(dev))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Device index must not be negative"
     ]
    }
   ],
   "source": [
    "R_quat, R_x = tg.rsample(R_mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e38ea1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.bmm(torch.transpose(R_x, 1, 2), R_x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05f04cc9",
   "metadata": {},
   "source": [
    "# Test torch_tsgaussian normal_term"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50d74439",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.ones(3).reshape((1,3))\n",
    "sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8b3ec1f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tg.normal_term(sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b9044e5",
   "metadata": {},
   "source": [
    "# Test torch_tsgaussian log_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15355144",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_1 = torch.eye(3).reshape((1, 3, 3))\n",
    "R_2 = torch.eye(3).reshape((1, 3, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42f5a3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tg.log_map(R_1, R_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ed69c3f",
   "metadata": {},
   "source": [
    "# Test torch_tsgaussian log_probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73cf0184",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_x = torch.eye(3).reshape((1,3,3))\n",
    "R_mu = torch.zeros(3,3).reshape((1,3,3))\n",
    "R_x = R_x.repeat(5, 1, 1)\n",
    "R_mu = R_mu.repeat(5, 1, 1)\n",
    "sigma = torch.ones(3).reshape((1,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bea27b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tg.log_probs(R_x, R_mu, sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb9c7699",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.e ** (-2.7568)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44e018f4",
   "metadata": {},
   "source": [
    "all codes run for torch_tsgaussian now, need to check it's correctness and make it into batch version."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b95795d",
   "metadata": {},
   "source": [
    "# Test TangentSpaceGaussian actions_from_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bafd90c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsg = TSG(None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f44a58a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(tsg.distribution)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00868675",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5783e46b",
   "metadata": {},
   "outputs": [],
   "source": [
    "tsg.actions_from_params(torch.eye(3).reshape((1,3,3)), torch.ones(3).reshape((1,3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91e4944d",
   "metadata": {},
   "source": [
    "# Test TangentSpaceGaussian log_prob_from_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff466764",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.eye(3).repeat(2,1,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2273f66f",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.ones(3).repeat(2,1).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7182d4ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# tsg.log_prob_from_params(torch.eye(3).repeat(2,1,1), torch.ones(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20db7927",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.randn(2, 4, 4)\n",
    "y = torch.linalg.inv(x)\n",
    "y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35c37abc",
   "metadata": {},
   "source": [
    "Again, codes can run, but need to check correctness."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4b68ac",
   "metadata": {},
   "source": [
    "# Try to run training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cdcd034",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from absl import app, flags\n",
    "from stable_baselines3 import SAC, PPO\n",
    "from envs.wahba import Wahba\n",
    "from stable_baselines_utils import CustomSACPolicy, \\\n",
    "    CustomCNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c1bc08b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(argv):\n",
    "    env = Wahba()\n",
    "    device = torch.device('cpu')\n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = dict(features_dim = 256))\n",
    "    policy_kwargs['n_critics'] = 1\n",
    "    policy_kwargs['share_features_extractor'] = False\n",
    "    policy = CustomSACPolicy\n",
    "    model = SAC(policy, env, verbose = 1, ent_coef = 'auto_0.1',\n",
    "                policy_kwargs = policy_kwargs, device = device)\n",
    "    model.learn(total_timesteps = 500, eval_freq = 100, n_eval_episodes = 100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0e5bf191",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.00033546262790251196"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.e ** (-8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "81415ccb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cpu device\n",
      "Wrapping the env with a `Monitor` wrapper\n",
      "Wrapping the env in a DummyVecEnv.\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.3     |\n",
      "| time/              |          |\n",
      "|    episodes        | 4        |\n",
      "|    fps             | 727      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 4        |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.17    |\n",
      "| time/              |          |\n",
      "|    episodes        | 8        |\n",
      "|    fps             | 721      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 8        |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.62    |\n",
      "| time/              |          |\n",
      "|    episodes        | 12       |\n",
      "|    fps             | 697      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 12       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.58    |\n",
      "| time/              |          |\n",
      "|    episodes        | 16       |\n",
      "|    fps             | 656      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 16       |\n",
      "---------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_6623/627403923.py:2: UserWarning: Anomaly Detection has been enabled. This mode will increase the runtime and should only be enabled for debugging.\n",
      "  with autograd.detect_anomaly():\n",
      "/home/fantasticoven/.local/lib/python3.8/site-packages/gym/logger.py:30: UserWarning: \u001b[33mWARN: Box bound precision lowered by casting to float32\u001b[0m\n",
      "  warnings.warn(colorize('%s: %s'%('WARN', msg % args), 'yellow'))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.62    |\n",
      "| time/              |          |\n",
      "|    episodes        | 20       |\n",
      "|    fps             | 613      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 20       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.67    |\n",
      "| time/              |          |\n",
      "|    episodes        | 24       |\n",
      "|    fps             | 627      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 24       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.61    |\n",
      "| time/              |          |\n",
      "|    episodes        | 28       |\n",
      "|    fps             | 641      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 28       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.73    |\n",
      "| time/              |          |\n",
      "|    episodes        | 32       |\n",
      "|    fps             | 654      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 32       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.87    |\n",
      "| time/              |          |\n",
      "|    episodes        | 36       |\n",
      "|    fps             | 667      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 36       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.91    |\n",
      "| time/              |          |\n",
      "|    episodes        | 40       |\n",
      "|    fps             | 679      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 40       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.83    |\n",
      "| time/              |          |\n",
      "|    episodes        | 44       |\n",
      "|    fps             | 679      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 44       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.76    |\n",
      "| time/              |          |\n",
      "|    episodes        | 48       |\n",
      "|    fps             | 671      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 48       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.81    |\n",
      "| time/              |          |\n",
      "|    episodes        | 52       |\n",
      "|    fps             | 671      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 52       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.9     |\n",
      "| time/              |          |\n",
      "|    episodes        | 56       |\n",
      "|    fps             | 670      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 56       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -5.96    |\n",
      "| time/              |          |\n",
      "|    episodes        | 60       |\n",
      "|    fps             | 668      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 60       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.04    |\n",
      "| time/              |          |\n",
      "|    episodes        | 64       |\n",
      "|    fps             | 679      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 64       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.08    |\n",
      "| time/              |          |\n",
      "|    episodes        | 68       |\n",
      "|    fps             | 691      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 68       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.05    |\n",
      "| time/              |          |\n",
      "|    episodes        | 72       |\n",
      "|    fps             | 701      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 72       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.06    |\n",
      "| time/              |          |\n",
      "|    episodes        | 76       |\n",
      "|    fps             | 712      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 76       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.08    |\n",
      "| time/              |          |\n",
      "|    episodes        | 80       |\n",
      "|    fps             | 722      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 80       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.02    |\n",
      "| time/              |          |\n",
      "|    episodes        | 84       |\n",
      "|    fps             | 732      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 84       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.05    |\n",
      "| time/              |          |\n",
      "|    episodes        | 88       |\n",
      "|    fps             | 742      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 88       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.13    |\n",
      "| time/              |          |\n",
      "|    episodes        | 92       |\n",
      "|    fps             | 751      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 92       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.1     |\n",
      "| time/              |          |\n",
      "|    episodes        | 96       |\n",
      "|    fps             | 760      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 96       |\n",
      "---------------------------------\n",
      "---------------------------------\n",
      "| rollout/           |          |\n",
      "|    ep_len_mean     | 1        |\n",
      "|    ep_rew_mean     | -6.14    |\n",
      "| time/              |          |\n",
      "|    episodes        | 100      |\n",
      "|    fps             | 753      |\n",
      "|    time_elapsed    | 0        |\n",
      "|    total_timesteps | 100      |\n",
      "---------------------------------\n",
      "-1\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Device index must not be negative",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     10\u001b[0m policy \u001b[38;5;241m=\u001b[39m CustomSACPolicy\n\u001b[1;32m     11\u001b[0m model \u001b[38;5;241m=\u001b[39m SAC(policy, env, verbose \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m, ent_coef \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mauto_0.1\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     12\u001b[0m             policy_kwargs \u001b[38;5;241m=\u001b[39m policy_kwargs, device \u001b[38;5;241m=\u001b[39m device)\n\u001b[0;32m---> 13\u001b[0m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m500\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/sac/sac.py:292\u001b[0m, in \u001b[0;36mSAC.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    279\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlearn\u001b[39m(\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    281\u001b[0m     total_timesteps: \u001b[38;5;28mint\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    289\u001b[0m     reset_num_timesteps: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[1;32m    290\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m OffPolicyAlgorithm:\n\u001b[0;32m--> 292\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mSAC\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtotal_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtotal_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    295\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    296\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_env\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_env\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    297\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    298\u001b[0m \u001b[43m        \u001b[49m\u001b[43mn_eval_episodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mn_eval_episodes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    299\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtb_log_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtb_log_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    300\u001b[0m \u001b[43m        \u001b[49m\u001b[43meval_log_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43meval_log_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    301\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreset_num_timesteps\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    302\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:354\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.learn\u001b[0;34m(self, total_timesteps, callback, log_interval, eval_env, eval_freq, n_eval_episodes, tb_log_name, eval_log_path, reset_num_timesteps)\u001b[0m\n\u001b[1;32m    351\u001b[0m callback\u001b[38;5;241m.\u001b[39mon_training_start(\u001b[38;5;28mlocals\u001b[39m(), \u001b[38;5;28mglobals\u001b[39m())\n\u001b[1;32m    353\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_timesteps \u001b[38;5;241m<\u001b[39m total_timesteps:\n\u001b[0;32m--> 354\u001b[0m     rollout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcollect_rollouts\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    355\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    356\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_freq\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain_freq\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    357\u001b[0m \u001b[43m        \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    358\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallback\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallback\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    359\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    360\u001b[0m \u001b[43m        \u001b[49m\u001b[43mreplay_buffer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreplay_buffer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    361\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlog_interval\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlog_interval\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    362\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    364\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m rollout\u001b[38;5;241m.\u001b[39mcontinue_training \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m:\n\u001b[1;32m    365\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:584\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm.collect_rollouts\u001b[0;34m(self, env, callback, train_freq, replay_buffer, action_noise, learning_starts, log_interval)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mactor\u001b[38;5;241m.\u001b[39mreset_noise(env\u001b[38;5;241m.\u001b[39mnum_envs)\n\u001b[1;32m    583\u001b[0m \u001b[38;5;66;03m# Select action randomly or according to policy\u001b[39;00m\n\u001b[0;32m--> 584\u001b[0m actions, buffer_actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_sample_action\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlearning_starts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maction_noise\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_envs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    586\u001b[0m \u001b[38;5;66;03m# Rescale and perform action\u001b[39;00m\n\u001b[1;32m    587\u001b[0m new_obs, rewards, dones, infos \u001b[38;5;241m=\u001b[39m env\u001b[38;5;241m.\u001b[39mstep(actions)\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/off_policy_algorithm.py:415\u001b[0m, in \u001b[0;36mOffPolicyAlgorithm._sample_action\u001b[0;34m(self, learning_starts, action_noise, n_envs)\u001b[0m\n\u001b[1;32m    410\u001b[0m     unscaled_action \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space\u001b[38;5;241m.\u001b[39msample() \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_envs)])\n\u001b[1;32m    411\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    412\u001b[0m     \u001b[38;5;66;03m# Note: when using continuous actions,\u001b[39;00m\n\u001b[1;32m    413\u001b[0m     \u001b[38;5;66;03m# we assume that the policy uses tanh to scale the action\u001b[39;00m\n\u001b[1;32m    414\u001b[0m     \u001b[38;5;66;03m# We use non-deterministic action in the case of SAC, for TD3, it does not matter\u001b[39;00m\n\u001b[0;32m--> 415\u001b[0m     unscaled_action, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_last_obs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;66;03m# Rescale the action from [low, high] to [-1, 1]\u001b[39;00m\n\u001b[1;32m    418\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39maction_space, gym\u001b[38;5;241m.\u001b[39mspaces\u001b[38;5;241m.\u001b[39mBox):\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/base_class.py:562\u001b[0m, in \u001b[0;36mBaseAlgorithm.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    542\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpredict\u001b[39m(\n\u001b[1;32m    543\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    544\u001b[0m     observation: np\u001b[38;5;241m.\u001b[39mndarray,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    547\u001b[0m     deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m    548\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[np\u001b[38;5;241m.\u001b[39mndarray, Optional[Tuple[np\u001b[38;5;241m.\u001b[39mndarray, \u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m]]]:\n\u001b[1;32m    549\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;124;03m    Get the policy action from an observation (and optional hidden state).\u001b[39;00m\n\u001b[1;32m    551\u001b[0m \u001b[38;5;124;03m    Includes sugar-coating to handle different observations (e.g. normalizing images).\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    560\u001b[0m \u001b[38;5;124;03m        (used in recurrent policies)\u001b[39;00m\n\u001b[1;32m    561\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpolicy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mepisode_start\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/policies.py:338\u001b[0m, in \u001b[0;36mBasePolicy.predict\u001b[0;34m(self, observation, state, episode_start, deterministic)\u001b[0m\n\u001b[1;32m    335\u001b[0m observation, vectorized_env \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mobs_to_tensor(observation)\n\u001b[1;32m    337\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m th\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 338\u001b[0m     actions \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[38;5;66;03m# Convert to numpy\u001b[39;00m\n\u001b[1;32m    340\u001b[0m actions \u001b[38;5;241m=\u001b[39m actions\u001b[38;5;241m.\u001b[39mcpu()\u001b[38;5;241m.\u001b[39mnumpy()\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/sac/policies.py:359\u001b[0m, in \u001b[0;36mSACPolicy._predict\u001b[0;34m(self, observation, deterministic)\u001b[0m\n\u001b[1;32m    358\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_predict\u001b[39m(\u001b[38;5;28mself\u001b[39m, observation: th\u001b[38;5;241m.\u001b[39mTensor, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m th\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m--> 359\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mobservation\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/torch/nn/modules/module.py:889\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_slow_forward(\u001b[38;5;241m*\u001b[39m\u001b[38;5;28minput\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    888\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 889\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    890\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m itertools\u001b[38;5;241m.\u001b[39mchain(\n\u001b[1;32m    891\u001b[0m         _global_forward_hooks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m    892\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks\u001b[38;5;241m.\u001b[39mvalues()):\n\u001b[1;32m    893\u001b[0m     hook_result \u001b[38;5;241m=\u001b[39m hook(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m, result)\n",
      "File \u001b[0;32m~/Desktop/DeepRotation/torch_ver/stable_baselines_utils.py:93\u001b[0m, in \u001b[0;36mCustomSACActor.forward\u001b[0;34m(self, obs, deterministic)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, obs: Tensor, deterministic: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     92\u001b[0m     mu, sigma, kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_action_dist_params(obs)\n\u001b[0;32m---> 93\u001b[0m     action \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43maction_dist\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mactions_from_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msigma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     94\u001b[0m \u001b[43m                                                \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     95\u001b[0m \u001b[43m                                                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# print('action: ', action)\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m action\n",
      "File \u001b[0;32m~/Desktop/DeepRotation/torch_ver/stable_baselines_utils.py:49\u001b[0m, in \u001b[0;36mTangentSpaceGaussian.actions_from_params\u001b[0;34m(self, mu, sigma, deterministic)\u001b[0m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproba_distribution(mu, sigma)\n\u001b[1;32m     46\u001b[0m \u001b[38;5;66;03m# actions = self.get_actions(deterministic = deterministic)\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \u001b[38;5;66;03m# print('actions size: ', actions.size())\u001b[39;00m\n\u001b[1;32m     48\u001b[0m \u001b[38;5;66;03m# print('actions type: ', type(actions))\u001b[39;00m\n\u001b[0;32m---> 49\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_actions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdeterministic\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/.local/lib/python3.8/site-packages/stable_baselines3/common/distributions.py:79\u001b[0m, in \u001b[0;36mDistribution.get_actions\u001b[0;34m(self, deterministic)\u001b[0m\n\u001b[1;32m     77\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m deterministic:\n\u001b[1;32m     78\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode()\n\u001b[0;32m---> 79\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msample\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/DeepRotation/torch_ver/stable_baselines_utils.py:35\u001b[0m, in \u001b[0;36mTangentSpaceGaussian.sample\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msample\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m     34\u001b[0m     \u001b[38;5;124;03m\"\"\"Need to be implemented\"\"\"\u001b[39;00m\n\u001b[0;32m---> 35\u001b[0m     s, s_mat \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdistribution\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrsample\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmu\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msigma\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     36\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m s, s_mat\n",
      "File \u001b[0;32m~/Desktop/DeepRotation/torch_ver/tsGaussian/torch_tsgaussian.py:52\u001b[0m, in \u001b[0;36mTangentSpaceGaussian.rsample\u001b[0;34m(self, R_mu, sigma)\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[38;5;28mprint\u001b[39m(dev)\n\u001b[1;32m     51\u001b[0m \u001b[38;5;66;03m# print('sigma: ', sigma)\u001b[39;00m\n\u001b[0;32m---> 52\u001b[0m omega \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mnormal(\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m3\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdev\u001b[49m\u001b[43m)\u001b[49m, sigma)\n\u001b[1;32m     53\u001b[0m \u001b[38;5;66;03m# print(R_mu.size())\u001b[39;00m\n\u001b[1;32m     54\u001b[0m R_x \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(R_mu, SO3\u001b[38;5;241m.\u001b[39mexp(omega\u001b[38;5;241m.\u001b[39mcpu())\u001b[38;5;241m.\u001b[39mas_matrix()\u001b[38;5;241m.\u001b[39mto(dev))\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Device index must not be negative"
     ]
    }
   ],
   "source": [
    "from torch import autograd\n",
    "with autograd.detect_anomaly():\n",
    "    env = Wahba()\n",
    "    device = torch.device(\n",
    "        \"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "    policy_kwargs = dict(\n",
    "        features_extractor_class = CustomCNN,\n",
    "        features_extractor_kwargs = dict(features_dim = 256))\n",
    "    policy_kwargs['n_critics'] = 1\n",
    "    policy_kwargs['share_features_extractor'] = False\n",
    "    policy = CustomSACPolicy\n",
    "    model = SAC(policy, env, verbose = 1, ent_coef = 'auto_0.1',\n",
    "                policy_kwargs = policy_kwargs, device = device)\n",
    "    model.learn(total_timesteps = 500, eval_freq = 100, n_eval_episodes = 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a782dad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dadc811",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_action = env.action_space.sample()\n",
    "random_action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e6cda8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = env.step(random_action)[0]\n",
    "obs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c6d3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "act = model.predict(obs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69029c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "act"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc12663b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import datetime\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorboard.backend.event_processing import event_accumulator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b673f35d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard --logdir ./sac"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03ebe69",
   "metadata": {},
   "source": [
    "# Experiments for batch operations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9e89d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigma = torch.ones(1, 3)\n",
    "omiga = torch.normal(torch.zeros(1, 3), sigma)\n",
    "omiga"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13560074",
   "metadata": {},
   "outputs": [],
   "source": [
    "def transfer(omiga):\n",
    "    omiga_0, omiga_1, omiga_2 = omiga[0], omiga[1], omiga[2]\n",
    "    omiga_hat = torch.tensor([[0, -omiga_2, omiga_1],\n",
    "                                [omiga_2, 0, -omiga_0],\n",
    "                                [-omiga_1, omiga_0, 0]])\n",
    "    return omiga_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59d1652a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functorch import vmap\n",
    "batch_transfer = vmap(transfer)\n",
    "batch_transfer(omiga)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f6f4f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from liegroups.torch import SO3\n",
    "C = SO3.exp(torch.Tensor([[1,2,3],\n",
    "                          [0,0,0]]))\n",
    "print(torch.Tensor([[1,2,3],\n",
    "                          [0,0,0]]).size())\n",
    "SO3.log(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3465633e",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.log(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46008e94",
   "metadata": {},
   "source": [
    "# Question to ask: the original wahba problem action is (4,), in our case actions are (3,3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cc5df3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
